python main.py --kd_inputs_worst True --use_logit True  --sample_method 'multi' --new_cand_mask True --exclude_eos False  --report_to tensorboard --seed 2022 --use_all_probs False --cand_num 1 --sample_num 63 --kd_inputs True --margin 0.001 --add_rl_loss True  --seq_decode_model bart --smooth 0.1 --sample_topk -1   --trainer rl --eos_replace False --post_replace False --save_steps 10000000 --rewards '116_rouge' --rewards_weight '1' --rl_weight 20 --batch_mean False --exp_name exp_bart_1109_20_eosf1437_logit --mask_rate 0.4 --rl_config local.more6.not.unirl.ini  --scene bart_cnn_generation --do_train --per_device_train_batch_size 8 --gradient_accumulation_steps 2 --learning_rate 0.000003 --num_train_epochs 60 --max_grad_norm 1 --print_every 1000 --save_every 4000 --eval_steps 1000 --per_device_eval_batch_size 32 --eval_metrics rouges,rouge --tokenizer_name t5-small --model facebook/bart-large-cnn  --recover ft0  --base_model_predict_file cnn_base_predict.txt --length_normalize_4_rl --training_length_penalty 1 --recover ''    --per_device_train_batch_size 4 --gradient_accumulation_steps 4 --per_device_eval_batch_size 32 --recover zr_output/ftbriocased_rl_3/_t5_model.41889_11999 --sample_num 63 --mask_rate 0.4 --rl_weight 1 --exp_name ftbriocased_rl_0.2 --eval_steps 2000 --learning_rate 0.000001 --print_every 2000   --recover sample/_t5_model.41889_11999 --rl_weight 0.2 --eval_dir sample/cnn_valid_no_pre --train_dir sample/cnn_train_no_pre_brio_untok_cased --recover ../DeepGen_rep/zr_output/ft32_2_t5_model.1999_3999 --mask_rate 0.25 --rl_weight 10 --new_cand_mask_y_s True --sample_num 31 --per_device_train_batch_size 4 --eval_steps 1000 --rouge_type 12l  --mask_rate 0.25   --pt False --rl_weight 30 --recover sample/_t5_model.43889_7999 --cand_pos_remove_sp_tk True --save_every 4000 --per_device_train_batch_size 3 --eval_steps 2000 --recover cnn_ft0_model --nmask_comma False --mask_rate 0.7 --fix_mask False  --recover cnn_ft0_model --exp_name 0.7 --rl_weight 40 --sample_num 31 --per_device_train_batch_size 2 --gradient_accumulation_steps 8 --exp_name mask310.740_best  --task seq2seq --reward_type rouges --eval_steps 1