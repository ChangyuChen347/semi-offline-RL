#!/bin/bash
CUDA_VISIBLE_DEVICES=2 python main.py \
    --do_train \
    --scene bart_samsum_generation \
    --use_logit True \
    --report_to tensorboard \
    --seed 2022 \
    --smooth 0 \
    --trainer rl \
    --save_steps 10000000 \
    --rewards 'rouge' \
    --rl_weight 3 \
    --batch_mean False \
    --exp_name exp_bart_samsum_mask0.4_526 \
    --per_device_train_batch_size 4 \
    --gradient_accumulation_steps 16 \
    --learning_rate 0.000001 \
    --num_train_epochs 60 \
    --max_grad_norm 4 \
    --print_every 200 \
    --save_every 200 \
    --eval_steps 400 \
    --per_device_eval_batch_size 32 \
    --eval_metrics rouges,rouge \
    --reward_type rouges \
    --length_normalize_4_rl True \
    --training_length_penalty 1 \
    --train_dir static_data/samsum/samsum_train.tsv \
    --eval_dir static_data/samsum/samsum_test.tsv \
    --model facebook/bart-large-xsum \
    --recover '' \
    --do_rl True \
    --per_device_train_batch_size 1 \
    --kd_inputs_worst True \
    --recover samsum_base_model \
    --sample_num 63 \
    --seq_decode_model bart \
    --rouge_type '12l' \
    --mask_rate 0.4 \
